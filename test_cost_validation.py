#!/usr/bin/env python3
"""
Task 0: Pre-PoC Cost Estimation and Validation Script

This script tests browser-use on real product pages to measure:
- Input/output token counts
- API call costs
- Anti-bot detection results
- Extraction success rates

Target budget: $0.05-0.10 per page
OpenAI Pricing (as of 2026):
- gpt-4o: $0.005/1K input, $0.015/1K output tokens
- gpt-4o-mini: $0.00015/1K input, $0.0006/1K output tokens

Usage:
    export OPENAI_API_KEY="your-key-here"
    python test_cost_validation.py
"""

import os
import sys
import json
import asyncio
import time
from datetime import datetime
from typing import Dict, List, Any, Optional
from dataclasses import dataclass, asdict
from dotenv import load_dotenv

# Load environment variables
load_dotenv("/Users/nickborrello/Desktop/Projects/BayState/.env.local")

# Import browser-use and langchain
from browser_use import Agent, Browser
from browser_use.llm import ChatOpenAI

# Constants
COST_PER_1K_INPUT_GPT4O = 0.005
COST_PER_1K_OUTPUT_GPT4O = 0.015
COST_PER_1K_INPUT_GPT4O_MINI = 0.00015
COST_PER_1K_OUTPUT_GPT4O_MINI = 0.0006


@dataclass
class ExtractionResult:
    """Result of a single extraction attempt"""

    url: str
    site: str
    sku: str
    success: bool
    execution_time_seconds: float
    input_tokens: int
    output_tokens: int
    model: str
    cost_usd: float
    extracted_data: Dict[str, Any]
    anti_bot_triggered: bool
    error_message: Optional[str] = None
    captcha_detected: bool = False
    block_message: Optional[str] = None


@dataclass
class CostValidationReport:
    """Complete cost validation report"""

    timestamp: str
    total_extractions: int
    successful_extractions: int
    failed_extractions: int
    avg_cost_per_page: float
    min_cost: float
    max_cost: float
    avg_execution_time: float
    anti_bot_blocks: int
    results: List[Dict[str, Any]]
    recommendations: str


def calculate_cost(input_tokens: int, output_tokens: int, model: str = "gpt-4o") -> float:
    """Calculate cost in USD for token usage"""
    if "mini" in model.lower():
        input_cost = (input_tokens / 1000) * COST_PER_1K_INPUT_GPT4O_MINI
        output_cost = (output_tokens / 1000) * COST_PER_1K_OUTPUT_GPT4O_MINI
    else:
        input_cost = (input_tokens / 1000) * COST_PER_1K_INPUT_GPT4O
        output_cost = (output_tokens / 1000) * COST_PER_1K_OUTPUT_GPT4O
    return input_cost + output_cost


async def extract_with_browser_use(url: str, site: str, sku: str, model: str = "gpt-4o-mini") -> ExtractionResult:
    """
    Extract product data from a URL using browser-use

    Returns:
        ExtractionResult with cost metrics and extraction data
    """
    start_time = time.time()

    try:
        # Initialize browser
        browser = Browser(headless=True)

        # Initialize LLM
        llm = ChatOpenAI(model=model, temperature=0.0, api_key=os.getenv("OPENAI_API_KEY"))

        # Create extraction agent with limited steps to avoid infinite loops
        agent = Agent(
            task=f"""Extract the following product information from {url}:
            1. Product Name
            2. Price (if available)
            3. Brand/Manufacturer
            4. Product Description (brief)
            5. Main Image URL (if available)
            6. Availability/Stock status
            
            Return the data in a structured format with these exact field names.
            If a field is not found, indicate "N/A".
            
            Product SKU to look for: {sku}
            
            IMPORTANT: If you encounter any human verification, CAPTCHA, or "Press & Hold" challenges,
            stop immediately and report that anti-bot measures were triggered.
            """,
            llm=llm,
            browser=browser,
            max_steps=10,  # Limit steps to prevent infinite loops
        )

        # Run the agent with timeout
        result = await asyncio.wait_for(agent.run(), timeout=120)

        execution_time = time.time() - start_time

        # Get token usage from result (estimate based on typical usage)
        # browser-use result object structure varies by version
        result_text = str(result) if result else ""

        # Estimate tokens based on result length (rough approximation)
        input_tokens = len(result_text) // 4 if result_text else 1000  # Estimate if not available
        output_tokens = len(result_text) // 8 if result_text else 500  # Estimate if not available

        # Check for anti-bot indicators in result
        anti_bot_triggered = False
        captcha_detected = False
        block_message = None

        anti_bot_indicators = [
            "captcha",
            "robot",
            "blocked",
            "access denied",
            "unusual traffic",
            "verify you are human",
            "security check",
            "human verification",
            "press & hold",
            "challenge",
        ]

        for indicator in anti_bot_indicators:
            if indicator.lower() in result_text.lower():
                anti_bot_triggered = True
                if "captcha" in result_text.lower():
                    captcha_detected = True
                block_message = f"Detected indicator: {indicator}"
                break

        # Parse extracted data
        extracted_data = {
            "raw_result": result_text[:2000]  # Limit size
        }

        # Calculate cost
        cost = calculate_cost(input_tokens, output_tokens, model)

        return ExtractionResult(
            url=url,
            site=site,
            sku=sku,
            success=True,
            execution_time_seconds=execution_time,
            input_tokens=input_tokens,
            output_tokens=output_tokens,
            model=model,
            cost_usd=cost,
            extracted_data=extracted_data,
            anti_bot_triggered=anti_bot_triggered,
            captcha_detected=captcha_detected,
            block_message=block_message,
        )

    except asyncio.TimeoutError:
        execution_time = time.time() - start_time
        error_message = "Operation timed out (120s limit) - likely due to anti-bot verification loop"

        return ExtractionResult(
            url=url,
            site=site,
            sku=sku,
            success=False,
            execution_time_seconds=execution_time,
            input_tokens=0,
            output_tokens=0,
            model=model,
            cost_usd=0.0,
            extracted_data={},
            anti_bot_triggered=True,  # Timeout usually indicates anti-bot
            error_message=error_message,
            captcha_detected=False,
            block_message="Timeout - likely anti-bot verification challenge",
        )
    except Exception as e:
        execution_time = time.time() - start_time
        error_message = str(e)

        # Check if error is anti-bot related
        anti_bot_keywords = ["captcha", "blocked", "denied", "robot", "human verification", "challenge", "verify"]
        anti_bot_triggered = any(indicator in error_message.lower() for indicator in anti_bot_keywords)

        return ExtractionResult(
            url=url,
            site=site,
            sku=sku,
            success=False,
            execution_time_seconds=execution_time,
            input_tokens=0,
            output_tokens=0,
            model=model,
            cost_usd=0.0,
            extracted_data={},
            anti_bot_triggered=anti_bot_triggered,
            error_message=error_message,
            captcha_detected="captcha" in error_message.lower(),
            block_message=error_message if anti_bot_triggered else None,
        )


async def run_cost_validation():
    """Run the full cost validation test suite"""

    print("=" * 80)
    print("Task 0: Pre-PoC Cost Estimation and Validation")
    print("=" * 80)
    print()

    # Test sites and SKUs (from walmart.yaml config)
    test_cases = [
        {
            "site": "walmart",
            "sku": "035585499741",
            "url": "https://www.walmart.com/search?q=035585499741",
            "product_url": None,  # Will be determined after search
        },
        {"site": "walmart", "sku": "079105116708", "url": "https://www.walmart.com/search?q=079105116708", "product_url": None},
        {"site": "walmart", "sku": "029695285400", "url": "https://www.walmart.com/search?q=029695285400", "product_url": None},
    ]

    # Alternative: Use direct product URLs if available
    direct_test_urls = [
        {"site": "walmart", "sku": "035585499741", "url": "https://www.walmart.com/ip/035585499741", "note": "Direct product URL attempt"},
        {"site": "amazon", "sku": "079105116708", "url": "https://www.amazon.com/s?k=079105116708", "note": "Amazon search page"},
        {"site": "amazon", "sku": "B00P6Y7N82", "url": "https://www.amazon.com/dp/B00P6Y7N82", "note": "Amazon ASIN direct"},
    ]

    results = []

    print(f"Running {len(direct_test_urls)} extraction tests...")
    print()

    # Check API key
    if not os.getenv("OPENAI_API_KEY"):
        print("ERROR: OPENAI_API_KEY not set!")
        print("Please set it with: export OPENAI_API_KEY='your-key'")
        sys.exit(1)

    print(f"API Key: {os.getenv('OPENAI_API_KEY')[:20]}...")
    print()

    # Run extractions
    for i, test_case in enumerate(direct_test_urls, 1):
        print(f"\n[{i}/{len(direct_test_urls)}] Testing {test_case['site']} - SKU: {test_case['sku']}")
        print(f"URL: {test_case['url']}")
        print(f"Note: {test_case.get('note', 'N/A')}")
        print("-" * 80)

        result = await extract_with_browser_use(
            url=test_case["url"],
            site=test_case["site"],
            sku=test_case["sku"],
            model="gpt-4o-mini",  # Use mini for cost efficiency during testing
        )

        results.append(result)

        # Print immediate results
        print(f"Success: {result.success}")
        print(f"Execution Time: {result.execution_time_seconds:.2f}s")
        print(f"Input Tokens: {result.input_tokens}")
        print(f"Output Tokens: {result.output_tokens}")
        print(f"Cost: ${result.cost_usd:.6f}")
        print(f"Anti-Bot Triggered: {result.anti_bot_triggered}")
        if result.error_message:
            print(f"Error: {result.error_message[:200]}")
        print()

    # Generate report
    successful = [r for r in results if r.success]
    failed = [r for r in results if not r.success]
    anti_bot_blocks = [r for r in results if r.anti_bot_triggered]

    if successful:
        avg_cost = sum(r.cost_usd for r in successful) / len(successful)
        min_cost = min(r.cost_usd for r in successful)
        max_cost = max(r.cost_usd for r in successful)
        avg_time = sum(r.execution_time_seconds for r in results) / len(results)
    else:
        avg_cost = min_cost = max_cost = avg_time = 0.0

    # Determine recommendations
    recommendations = []
    if avg_cost > 0.10:
        recommendations.append(f"‚ö†Ô∏è  COST OVERRUN: Average cost ${avg_cost:.4f} exceeds $0.10/page target")
        recommendations.append(f"   Recommendation: Switch to gpt-4o-mini or implement stricter limits")
    elif avg_cost > 0.05:
        recommendations.append(f"‚ö†Ô∏è  COST WARNING: Average cost ${avg_cost:.4f} is within target but on higher side")
        recommendations.append(f"   Recommendation: Monitor costs closely in production")
    else:
        recommendations.append(f"‚úÖ COST OK: Average cost ${avg_cost:.4f} is within budget ($0.05-0.10/page)")

    if len(anti_bot_blocks) > 0:
        block_rate = len(anti_bot_blocks) / len(results)
        recommendations.append(f"‚ö†Ô∏è  ANTI-BOT: {len(anti_bot_blocks)}/{len(results)} sites triggered anti-bot ({block_rate:.0%})")
        recommendations.append(f"   Recommendation: Implement fallback chain (AI ‚Üí Traditional ‚Üí Manual)")
    else:
        recommendations.append(f"‚úÖ ANTI-BOT: No anti-bot detection triggered")

    if len(failed) > 0:
        fail_rate = len(failed) / len(results)
        recommendations.append(f"‚ö†Ô∏è  SUCCESS RATE: {len(successful)}/{len(results)} successful ({(1 - fail_rate):.0%})")
        if fail_rate > 0.3:
            recommendations.append(f"   Recommendation: High failure rate may indicate issues with browser-use or site structure")
    else:
        recommendations.append(f"‚úÖ SUCCESS RATE: 100% ({len(successful)}/{len(results)})")

    # Create final report
    report = CostValidationReport(
        timestamp=datetime.now().isoformat(),
        total_extractions=len(results),
        successful_extractions=len(successful),
        failed_extractions=len(failed),
        avg_cost_per_page=avg_cost,
        min_cost=min_cost,
        max_cost=max_cost,
        avg_execution_time=avg_time,
        anti_bot_blocks=len(anti_bot_blocks),
        results=[asdict(r) for r in results],
        recommendations="\n".join(recommendations),
    )

    # Save evidence files
    evidence_dir = "/Users/nickborrello/Desktop/Projects/BayState/.sisyphus/evidence"

    # 1. Cost validation JSON
    cost_validation_path = os.path.join(evidence_dir, "task-0-cost-validation.json")
    with open(cost_validation_path, "w") as f:
        json.dump(
            {
                "timestamp": report.timestamp,
                "summary": {
                    "total_extractions": report.total_extractions,
                    "successful": report.successful_extractions,
                    "failed": report.failed_extractions,
                    "avg_cost_per_page": report.avg_cost_per_page,
                    "min_cost": report.min_cost,
                    "max_cost": report.max_cost,
                    "avg_execution_time": report.avg_execution_time,
                    "anti_bot_blocks": report.anti_bot_blocks,
                },
                "details": report.results,
            },
            f,
            indent=2,
            default=str,
        )
    print(f"\nüìÅ Saved cost validation to: {cost_validation_path}")

    # 2. Anti-bot results JSON
    antibot_path = os.path.join(evidence_dir, "task-0-antibot-results.json")
    antibot_results = [
        {
            "url": r.url,
            "site": r.site,
            "anti_bot_triggered": r.anti_bot_triggered,
            "captcha_detected": r.captcha_detected,
            "block_message": r.block_message,
            "success": r.success,
        }
        for r in results
    ]
    with open(antibot_path, "w") as f:
        json.dump(
            {
                "timestamp": report.timestamp,
                "total_sites_tested": len(results),
                "sites_blocked": len(anti_bot_blocks),
                "block_rate": len(anti_bot_blocks) / len(results) if results else 0,
                "results": antibot_results,
            },
            f,
            indent=2,
        )
    print(f"üìÅ Saved anti-bot results to: {antibot_path}")

    # Print summary
    print("\n" + "=" * 80)
    print("COST VALIDATION SUMMARY")
    print("=" * 80)
    print(f"Total Extractions: {report.total_extractions}")
    print(f"Successful: {report.successful_extractions}")
    print(f"Failed: {report.failed_extractions}")
    print(f"Anti-Bot Blocks: {report.anti_bot_blocks}")
    print()
    print(f"Average Cost Per Page: ${report.avg_cost_per_page:.6f}")
    print(f"Min Cost: ${report.min_cost:.6f}")
    print(f"Max Cost: ${report.max_cost:.6f}")
    print(f"Average Execution Time: {report.avg_execution_time:.2f}s")
    print()
    print("RECOMMENDATIONS:")
    print(report.recommendations)
    print()

    return report


if __name__ == "__main__":
    # Run the async test
    report = asyncio.run(run_cost_validation())

    # Exit with error code if critical issues
    if report.avg_cost_per_page > 0.30:
        print("‚ùå CRITICAL: Cost exceeds $0.30/page - aborting AI scraper implementation")
        sys.exit(1)
    elif report.anti_bot_blocks == report.total_extractions:
        print("‚ùå CRITICAL: All sites blocked - anti-bot measures too strong")
        sys.exit(1)
    else:
        print("‚úÖ Task 0 complete - proceeding with implementation")
        sys.exit(0)
